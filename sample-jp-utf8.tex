%%
% このファイルは，筑波大学情報学群情報メディア創成学類の
% 卒業研究論文本体のサンプルです．
% このファイルを書き換えて，この例と同じような書式の論文本体を
% LaTeXを使って作成することができます．
% 
% PC環境や，LaTeX環境の設定によっては漢字コードや改行コードを
% 変更する必要があります．
%%
\documentclass[a4paper,11pt]{jreport}

%%【PostScript, JPEG, PNG等の画像の貼り込み】
%% 利用するパッケージを選んでコメントアウトしてください．
%%
%% 推奨： graphicx パッケージ（本ファイルではこれを使用）
%%	動かない場合にいは \usepackage[dvipdfmx]{graphicx} のように dvi 変換コマンドを明示指定する．
%%
% \usepackage{graphicx} % for \includegraphics[width=3cm]{sample.eps}
% \usepackage[dvipdfm]{graphicx} % 画像の挿入に必要
\usepackage[dvipdfmx]{graphicx}
\usepackage[dvipdfmx]{color}
\usepackage{float} % 図の位置の強制指定に必要
%% 一応 OK (epsfig.sy)
% \usepackage{epsfig} % for \psfig{file=sample.eps,width=3cm}
%% 以下の２つの使用はあまり勧められない (epsf.sty, epsfbox.sty)
%\usepackage{epsf} % for \epsfile{file=sample.eps,scale=0.6}
%\usepackage{epsbox} % for \epsfile{file=sample.eps,scale=0.6}

\usepackage{times} % use Times Font instead of Computer Modern
\usepackage{mdframed}
\usepackage{latexsym} % 数式で使える記号を増やす
\usepackage{amsmath} % 数式の記述環境
\usepackage{fancyhdr} % ヘッダとフッタの設定に必要
\usepackage{algorithm,algpseudocode} % 疑似コードの記述に必要
\usepackage{array}
\usepackage{booktabs} % For formal tables
\usepackage{listings}

\setcounter{tocdepth}{3}	% 目次を3レベル (1.2.3) まで
\setcounter{secnumdepth}{3}	% 番号付けレベル． 3: \section まで 4: \subsubsection まで
\setcounter{page}{-1}

\setlength{\oddsidemargin}{0.1in}
\setlength{\evensidemargin}{0.1in} 
\setlength{\topmargin}{0in}
\setlength{\textwidth}{6in} 
%\setlength{\textheight}{10.1in}	% ページの縦幅を変更する場合には設定する
\setlength{\parskip}{0em}
\setlength{\topsep}{0em}

%% タイトル生成用パッケージ(重要)
\usepackage{mast-jp-utf8}

%% タイトル
%% 【注意】タイトルの最後に\\ を入れるとエラーになります
\title{大規模言語モデルを用いた語用論的\\アプローチに基づく誤解可能性を考慮した\\画像情報ラベリング}
%% 著者
\author{清野 駿}
%% 指導教員
\advisor{若林 啓}

%% 年月 (提出年月)
%% 年月は必要に応じて書き替えてください．
\majorfield{　} \yearandmonth{2024年 2月}



\begin{document}
\maketitle
\thispagestyle{empty}
\newpage

\thispagestyle{empty}
\vspace*{20pt plus 1fil}
\parindent=1zw
\noindent
%%
%% 論文の概要(Abstract)
%%
\begin{center}
{\bf 概要}
\vspace{5mm}
\end{center}
本研究では，複数の画像情報が与えられたときに，そのうちの一つを誤解なく指し示すことのできる自然言語ラベルを導出する手法を提案する．

% 背景
近年，画像情報に対して適切な自然言語ラベルを付与することのできる，マルチモーダルな学習済み大規模言語モデルが広く利用可能になっている．

% 課題
しかし，大量の画像情報を一度に処理して，それぞれに特有の特徴を反映した自然言語ラベルを付与することは容易ではない．

% 研究目的
本研究では，語用論に基づく「聞き手モデル」を導入し，内省的処理を通じてラベルの品質を向上させるアプローチを提案する．

% 手法
% 大規模言語モデルを素直に用いてラベルを生成する手法をベースライン手法とし，「聞き手モデル」を導入した「強化ベースライン手法」と，単語の組み合わせによるラベル生成・改善アルゴリズムを導入した「組合せ最適化手法」の2つの提案手法によって，それぞれラベルの品質を向上させる．

% 実験
実験ではベースライン手法と2つの提案手法の計3つの手法によってラベルを生成し，これらの手法によるラベルの誤解可能性を被験者実験を通じて比較した．
%%%%%
\par
\vspace{0pt plus 1fil}
\newpage

\pagenumbering{roman} % I, II, III, IV 
\tableofcontents
\listoffigures
%\listoftables		% 本ファイルでは省略してある

%% ここから本文
\pagebreak \setcounter{page}{1}
\pagenumbering{arabic} % 1,2,3


\chapter{はじめに}

画像情報に対して自然言語のテキストを生成する技術は，様々な産業的な応用への活用が期待される \cite{Yin2023}．
特に，複数の画像が与えられたときに，それらを誤解なく指し示すことのできるテキスト表現を生成することは，ロボットによる場所のナビゲーションや，人間に対する情報提供を正確に行う上で，重要なタスクである．
本稿では，与えられた複数の画像のそれぞれに対して，それらを互いに区別可能な自然言語ラベルを生成する問題を，画像情報ラベリングと呼ぶ．

画像情報を説明する自然言語テキストを生成する手法は，画像キャプション生成の分野で研究されている \cite{Farhadi2010,Vinyals2017,Dai2023}．
特に近年では，与えられた画像情報を説明する自然言語テキストの生成や，画像情報に関する質問に回答することのできる，マルチモーダルな事前学習済み大規模言語モデルが広く利用可能になっている \cite{Gan2022}．
深層学習モデルは，モデルの規模（パラメータ数）と訓練データの規模を増加させることで品質が向上し続ける傾向があり\cite{Devlin2019}，画像キャプション生成においても有効性が示されている．
このことから，可能な限り大きなスケールで事前学習した共有の大規模言語モデルを，再学習することなく活用する技術の検討が重要になってきている．

しかし，大規模言語モデルは，大量のデータをそのまま入力することはできないことから，多数のデータの関係を考慮した処理には適していない．
このため，複数の画像に対して，それらを区別する自然言語ラベルを生成する，画像情報ラベリングの問題設定における性能は十分に検証されていない．
似た画像と区別できるようなキャプションを生成する手法の研究は行われている\cite{Vedantam2017,Cohn-Gordon2018,Nie2020,Andreas2016}が，これらの研究ではキャプション生成モデルの学習を伴うことから，大規模言語モデルの性能を活用することができないという課題がある．

本研究では，画像情報ラベリングタスクにおいて，大規模言語モデルを用いたテキスト生成手法の性能を評価すると共に，語用論的アプローチに基づいて性能の向上ができるかどうかを検討する．
語用論的アプローチは，聞き手の解釈を考慮して，誤解を避けるような言語を生成するアプローチであり，複数のテキスト生成タスクにおける品質の向上が報告されている．
本研究では，2つの手法を通して，画像情報ラベリングにおける語用論的アプローチの有効性を検証する．
1つ目の手法では，大規模言語モデルに生成させた画像情報のラベルの中から，誤解の起きやすいラベルを検出し，再び大規模言語モデルに修正させる．
2つ目の手法では，大規模言語モデルに直接ラベルを生成させるのではなく，多数の特徴をテキストで挙げさせて，そのうちのいくつかを選択してラベルを構成する．
この選択においては，誤解の起きやすさを評価する聞き手モデルを内部的に持つことによって，誤解可能性を最小化するような特徴の組み合わせを発見する最適化手法を提案する．

複数の部屋の画像が与えられたときに，それぞれの部屋を指し示すラベルを生成する実験を行った．
生成したラベルの評価にはAmazon Mechanical Turkを利用し，人間がどの程度誤解するかを検証した．
実験の結果から，テキスト長が短いラベルにおいて，提案する語用論的アプローチによって性能が改善することを示す．

% 本論文では，画像に対するラベル生成における新たなアプローチを提案する．具体的には，語用論的な観点から話し手モデルと聞き手モデルを導入し，その対話を通じてラベルの改善を図る．この新たなアプローチは，生成されたラベルが画像を一意に特定できることを保証することを目的としている．また，生成したラベルの評価にはAmazon Mechanical Turkを利用し，生成されたラベルが人間にとってどの程度理解しやすいかを検証する．本論文では，提案手法とその評価結果について詳細に述べる．

% 関連研究
\chapter{関連研究}

本章では，本研究で扱う画像情報ラベリングタスクに関連する研究として，画像に基づくテキスト生成技術について\ref{sec:relwork_image_captioning}節で述べる．
また，提案手法の着想に関連する研究として，語用論的アプローチに基づく機械学習手法について\ref{sec:relwork_pragmatic_ml}節で述べる．

\section{画像に基づくテキスト生成}
\label{sec:relwork_image_captioning}
画像内容に基づくテキスト生成技術の発展は，画像キャプション生成の研究によって牽引されてきた \cite{Farhadi2010}．
特に，深層学習を用いた画像キャプション生成では，ニューラルネットワークに画像の特徴を抽出し，得られた特徴に基づいて再帰型ニューラルネットワークでテキストを生成するモデルの枠組みが用いられる \cite{Vinyals2017}．
この枠組みにおいてXuら\cite{Xu2015}は，注意機構を用いて画像内の注目すべき箇所の情報を抽出することで，生成されるキャプションの品質が向上することを示した．

一方近年，タスクによらない画像やテキストの表現学習によって，深層学習の性能が大幅に向上することが明らかになってきた \cite{Devlin2019}．
この知見を発展させて，画像とテキストのマルチモーダルモデルを構成し，これを大規模な画像とテキストのデータセットを用いて特徴量表現を学習する手法が研究されている \cite{Yin2023,Gan2022}．
事前学習済みの大規模マルチモーダルモデルを用いることで，画像キャプション生成の品質が向上する\cite{Dai2023}だけでなく，画像のゼロショット分類\cite{Radford2021}や，画像質問応答\cite{Song2022}などのタスクの精度も向上することも示されている．

さらに近年では，モデル規模と訓練データをスケールアップすることで，テキストでの指示（プロンプト）に応じた画像に基づくテキスト生成ができることが明らかになった．
Liら\cite{Li2023}は，事前訓練済みの画像特徴量抽出器とテキスト生成器の間を橋渡しするQuerying Transformerを訓練する手法によって，画像に関する自然な会話や，柔軟な指示に応じた説明の生成ができることを示した．
GPT-4\cite{Bubeck2023}は，入力した画像を描画するプログラムを出力したり，グラフの解釈もできることを示している．
例えば，「この画像の特徴を10個挙げてください」というプロンプトと共に画像を入力することで，自然言語テキストで画像の特徴を得ることができる．

これらの深層学習に基づく手法はブラックボックスであり，どこまでのタスクを実現できるかは未知数であるが，基本的には1枚あるいは少数の画像とテキストの間を結びつける処理を想定している．
このため，多数の画像に対して，それらを区別する自然言語ラベルを生成する問題設定における性能は十分に検証されていない．
本研究では，画像情報ラベリングタスクにおいて，これらのテキスト生成手法の性能を評価すると共に，画像情報ラベリングタスクを分割して再構成することによるタスク性能の向上を検討する．

\section{語用論的アプローチに基づく機械学習}
\label{sec:relwork_pragmatic_ml}
言語の生成にあたって，聞き手の解釈を考慮して，誤解を避けるような語を選ぶことは，コミュニケーションにおいて重要な要素である．
このような，話し手による聞き手の解釈を考慮したアプローチは，計算語用論と呼ばれる\cite{Fried2023}．
Rational Speech Acts (RSA)フレームワークは，計算語用論の代表的な計算モデルである \cite{Frank2012,Goodman2016}．
RSAフレームワークでは，話し手と聞き手のモデルが，それぞれ相手の目的や解釈について再帰的に推論する過程を計算する．
例えば，RSAフレームワークにおける話し手モデルは，内部的に持つ聞き手モデルに発話を解釈させたときに，伝達したい意図通りの解釈が得られるような発話を選択する．

この知見を反映して，RSAフレームワークに基づいてテキスト生成タスクの品質を向上させる手法が研究されている\cite{Fried2017}．
Williamら\cite{Williams2015}は，室内のナビゲーションタスクにおいて，計算語用論に基づく手法を提案した．
話し手モデルによって生成された複数の指示を聞き手モデルに入力し，聞き手モデルが意図通りに解釈する指示を出力する．
SAILデータセットを用いた評価により，語用論的アプローチによってナビゲーションの成功率が向上することが示された．

画像キャプション生成においても，語用論的アプローチによって，聞き手が似た画像と区別できるようなキャプションを生成する手法が提案されている\cite{Vedantam2017,Cohn-Gordon2018,Nie2020}．
Andreasら\cite{Andreas2016}は，画像の参照ゲームにおいて，聞き手の誤解を低減するようなキャプションを生成する手法を提案した．
これらの手法は，ニューラルネットワークでモデル化された話し手と聞き手の学習を伴うことから，近年極めて高い品質を達成している大規模事前学習済みモデルを活用することが難しい．
本研究では，大規模事前学習済みモデルを再学習することなく用いる語用論的アプローチによって，誤解可能性を考慮した画像情報ラベリングを実現する手法を検討する．

%提案手法
\chapter{提案手法}

\section{問題設定}

本研究では，画像の集合が入力されたときに，それぞれの画像を，人が一意に誤解なく特定できるラベルを生成する問題に取り組む．

n枚の画像の集合を\(X = \{x_1, x_2, \ldots, x_n\}\)とする．\(X\)に対して付与されるラベルの集合を\(Y = \{y_1, y_2, \ldots, y_n\}\)とする．ラベル\(y_1, y_2, \ldots, y_n\)は画像\(x_1, x_2, \ldots, x_n\)にそれぞれ対応しており，各ラベルは対応する画像の特徴を説明するものとする．

ここで，ラベル\(y_r\)（$r \in [1..n]$）と\(X\)を被験者に与えたとき，被験者が\(y_r\)に対応する画像\(x_r\)を選択しようとして，\(x_r\)以外を選択してしまう確率を誤解可能性\(p\)とする．

提案手法では，\(p\)が最小となるラベルの組み合わせ\(Y\)を生成することを目的とする．


\section{話し手モデルと聞き手モデル}

本研究の手法では，語用論的アプローチに基づき問題解決を図る．

語用論とは，話し手と聞き手が互いの意図を理解する過程を研究する学問であり，皮肉表現や比喩表現などを研究対象とする．

本研究での語用論的アプローチは，話し手モデルと聞き手モデルの対話を通じて，問題への回答を改善していく．

話し手モデルは，画像を詳細かつ正確に説明するラベルを生成することに重点を置く．この過程では，画像の特徴や意味内容を考慮し，誤解を引き起こす可能性のある曖昧な表現を避けることが重要である．一方，聞き手モデルは，生成されたラベルがどの程度誤解を招く可能性があるかを評価する．このモデルは，ラベルが提供する情報が明確で，かつ他のラベルとの誤解が起きないかどうかを評価し，話し手モデルに対してフィードバックを行う．
\subsection{話し手モデルと聞き手モデルの役割}

\begin{itemize}
  \item 話し手モデル：画像を説明するラベルを生成し，その改善を行う．
  \item 聞き手モデル：生成されたラベルに対する誤解可能性を評価し，各画像を誤解なく選択できるかを判断する．
\end{itemize}


% \section{ベースライン（ChatGPT手法）}
% プロンプトの説明中心
\section{Pragmatic ChatGPT（PCG）手法}

PCGでは，話し手モデルと聞き手モデルの両方をChatGPTを用いて実装し，ラベル生成を行う．

この手法では，以下のステップでラベルを生成し，繰り返し改善を図る．このステップでは，1，3が話し手モデル，2が聞き手モデルの役割を担っている．

\begin{enumerate}
  \item ChatGPTに対して画像の集合Xを入力する．Xに含まれる各画像に対して，それぞれ誤解なく画像を区別できるラベルを出力するように，プロンプトを入力する．ここで出力されたラベルの集合をY1とする．
  \item ラベルの集合Y1と画像の集合XをChatGPTに入力する．Y1に含まれる各ラベルについて誤解可能性を分析し，ラベル改善のヒントを出力するように，プロンプトを入力する．出力されたラベル改善のヒントをH1とする．
  \item ChatGPTに対して画像の集合X，ラベル改善のヒントH1，ラベルの集合Y1を入力する．H1を参考にして，Y1を改善した新たなラベルを出力するように，プロンプトを入力する．ここで出力されたラベルの集合をY2とする．
  \item 2と3を繰り返して，最終的に得られたラベルの集合Ym（mは任意の自然数）を，誤解可能性の低いラベルとして提出する．
\end{enumerate}

各モデルごとに行っている処理を以下に示す．

\begin{itemize}
  \item 話し手モデル（生成モデル）
    \begin{itemize}
      \item 初期ラベル生成：Xに含まれる各画像に対応するラベルY1を出力する．
      \item 改善ラベル生成：聞き手モデルによって出力されたヒントHと，X，Y1から，Y1を改善したラベルY2を出力する．
    \end{itemize}
  \item 聞き手モデル
    \begin{itemize}
      \item ヒント生成：XとY1から，ラベル改善のヒントHを出力する
    \end{itemize}
\end{itemize}
	
% プロンプトとその組み合わせ，サイクルの説明

\section{特徴量に基づく組み合わせ最適化手法}
\subsection{全体の流れ}
特徴量に基づく組合せ最適化手法（FCO）では，画像から特徴を表す単語群を生成し，これを基に最適なラベルを導き出していく．このプロセスは，話し手モデルと聞き手モデルの相互作用によって実現される．
以上の処理の流れをまとめた図を図\ref{fig:cof_flow_example}に示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=3.5in]{figures/COF_flow.jpg}
  \caption{ラベル生成の流れ}
  \label{fig:cof_flow_example}
\end{figure}

\subsection{特徴群生成とラベル生成}
初めに，話し手モデル（ChatGPT-4）に画像群$X$を入力し，各画像から特徴を表す単語群$Z$を生成する．特徴群$Z$の例は図\ref{fig:feature_group}に示す．この際，各画像からは50個の特徴$z$が得られる．次に，これらの特徴群$Z$からランダムに特徴を選び，組み合わせてラベル$y$を生成する．これを画像群$X$全体で行い，ラベル集合$Y_1$を作成する．

\begin{figure}[H]
\begin{mdframed}[linewidth=1pt]
Tray ceiling Recessed lighting, Beige wall paint, ..., Decorative straw hats on wall, Distressed wood mirror frame
\end{mdframed}
\caption{部屋X1の特徴群Z1}
\label{fig:feature_group}
\end{figure}

続いて，聞き手モデルに$Y_1$と$X$を入力する．このモデルは，各ラベルの誤解可能性を分析し，最も誤解性が高いラベル組をヒント$H_1$として出力する．
\subsection{ゼロショット画像分類}
生成されたラベルの誤解可能性を評価するため，ゼロショット画像分類を実施する．このプロセスでは，生成されたラベル群$Y_1$と単一の画像$x_1$を入力として与える．ゼロショット画像分類を適用し，画像$x_1$が各ラベルに属する確率を確率分布として出力する．
この手順は画像$x_1$から$x_n$に至るまで同様に行われる．
実際にゼロショット分類をした際の結果を図\ref{fig:zeroshot_result}に示す．
\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figures/zeroshot_result.png}
  \caption{ゼロショット分類の結果}
  \label{fig:zeroshot_result}
\end{figure}
\subsection{F1スコア計算}
ラベルセットの誤解可能性はゼロショット画像分類の結果を用いて計算されたF1スコアで評価される．
ゼロショット画像分類を行ったときに，$i$番目の画像に対して，$j$番目のラベルに与えられた確率を$p_{i,j}$とすると，ラベル$j$の適合率は$\frac{p_{j,j}}{\sum_i(p_{i,j})}$，再現率は$p_{j,j}$である．

ラベル$j$のF1スコアは，ラベル$j$の適合率と再現率の調和平均で求められる．そして全ラベル$Y$に対してそれぞれF1スコアを求め，全F1スコアの平均をラベルの性能とする．
\subsection{誤解性の高いラベルペア判定}
ゼロショット画像分類の結果を分析して改善すべきラベルのペアを特定する過程では，画像$x_k$を説明したラベル$y_k$とし，$x_k$以外の画像の中で$y_k$への所属確率が最も高いものを$y_1$から$y_n$で取得する．自分の画像以外の画像の所属確率が最も高いラベルと，最も高い画像の真の正解ラベルを改善ペアとして出力する．このペアは，ゼロショット分類において最も誤解されやすい，つまり最も性能が低いと判断されるラベルと，そのラベルが誤って関連付けられた画像の正しいラベルである．
\subsection{聞き手モデルから受け取ったヒントをもとにラベルを改善}
次に，話し手モデルに$H_1$を入力し，$Y_1$を改善した新たなラベル集合$Y_2$を生成する．この際，画像とテキストのペアを大規模に学習することで，画像の内容を説明するテキストとの類似度を計算できるモデルであるCLIP（Contrastive Language–Image Pre-training）を使用する．CLIPは，画像とテキストの両方を同じ空間に埋め込むことで，その類似度を測定する．ここでの類似度は画像とラベルの特徴の重要度として扱う．各特徴と画像との重要度の例は表\ref{tab:similarity_examples}に示す．

\begin{table}[ht]
\centering
\caption{各特徴と画像との重要度の具体例}
\label{tab:similarity_examples}
\begin{tabular}{@{}lr@{}}
\toprule
特徴 & 重要度 \\ \midrule
Tray ceiling Recessed lighting & 28.051437 \\
Two-tone wood flooring & 25.21447 \\
White ceiling & 25.036436 \\
\addlinespace % Adds some space before the dots
\multicolumn{2}{c}{\dots} \\ % Centered dots to indicate omitted data
\addlinespace % Adds some space after the dots
Mountainous landscape view & 17.63242 \\
Glass vase with white flowers & 17.470116 \\
Striped throw on the bed & 16.694729 \\ \bottomrule
\end{tabular}
\end{table}


与えられた改善すべき2つのラベルセット（\texttt{current\_label1}と\texttt{current\_label2}）に対して，それぞれのラベルセットが表す画像（\texttt{image1}と\texttt{image2}）との重要度を参考にしながら改善する処理を行う．以下にその処理をステップごとに説明する．

\begin{enumerate}
    \item \textbf{current\_label1 vs image1}\\
    \texttt{current\_label1}の中から，\texttt{image1}との類似度が最も低いラベルを確率的に選択．これは，類似度の逆数をソフトマックス関数にかけることで確率分布を作成し，その分布に基づいてランダムに選択することで行う．
    \item \textbf{all\_label1 vs image1}\\
    \texttt{all\_label1}の中から\texttt{current\_label1}に含まれていないラベルを対象に，\texttt{image1}との類似度が高いラベルから確率的に選択する．
    \item \textbf{current\_label1 vs image2}\\
    \texttt{current\_label1}の中から，\texttt{image2}との類似度が高いラベルを確率的に選択．これは，類似度をソフトマックス関数にかけることで確率分布を作成し，その分布に基づいてランダムに選択することで行う．
    \item \textbf{all\_label1 vs image2}\\
    \texttt{all\_label1}の中から\texttt{current\_label1}に含まれていないラベルを対象に，\texttt{image2}との類似度が低いラベルを確率的に選択する．
    \item \textbf{ラベルの入れ替え}\\
    \texttt{current\_label1}からステップ1で選んだラベルとステップ4で選んだラベルを除外し，ステップ2と3で選んだラベルを追加して新しいラベルセット\texttt{new\_label1}を作成する．
    \item \textbf{重複の削除}\\
    最後に，\texttt{new\_label1}と\texttt{new\_label2}から重複しているラベルを削除する．これにより，各ラベルセットがユニークなラベルのみを含むようになる．
    \item \textbf{curent\_label2でも同様の処理をしてnew\_label2を作成する．}
    \item \textbf{改善されたラベルセットの返却}\\
    処理を経て改善された\texttt{new\_label1}と\texttt{new\_label2}を関数の出力として返却する．
\end{enumerate}
これにより，\texttt{current\_label1}と\texttt{current\_label2}はそれぞれの画像に対する識別性が改善され，画像とラベルの関連性が高まるように調整される．
このプロセスを繰り返し，ラベル集合$Y_m$を誤解可能性が低くなるように改善していく．
最終的に，全試行の中で最も平均F1スコアが高い時のラベル組み合わせを出力する．
全試行内の平均F1スコアが以下の図\ref{fig:f1_score}の場合，赤丸の時のラベルセットを最終的な出力とする．
\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figures/f1_score.png}
  \caption{200回試行内のF1スコアの推移}
  \label{fig:f1_score}
\end{figure}
この手法では，話し手モデルが特徴群の生成，特徴の組み合わせによるラベル生成，ヒントに基づくラベルの改善を担い，聞き手モデルが各画像の選択の正確性評価，ラベルの誤解可能性の分析，改善すべきラベル組のヒント出力を行う．この相互作用により，画像に対する最適なラベルを効果的に生成することを試みる．

\section{特徴量に基づく組み合わせ最適化手法}
本節では，LLMに直接ラベルを生成させるのではなく，画像情報の特徴を列挙させ，そのうちのいくつかを選択してラベルを構成する提案手法について述べる．
提案手法は，聞き手がラベルを解釈し，指し示している画像の候補を絞り込む過程を明示的に考慮する．

画像 $x_i$ に対して，特徴量 $Z_i = \{z_1, \ldots, z_m\}$ を生成させる．$m$ は1枚の画像情報あたりの特徴量の数である．例えば，図xの部屋であれば，$z_1 = \text{'red bed'}$, $z_2 = \text{'...'}$ など




% 実験
\chapter{評価実験}

\section{実験設定}

本実験では，各手法の性能を比較するため，生成されたラベルの誤解可能性を検証する．被験者に複数の画像と1つのラベルを与え，対応する画像を選択できるかを調査する．

ラベルの生成には以下の3つの手法を用いる．
\begin{enumerate}
    \item ChatGPTを用いたベースライン手法
    \item Pragmatic ChatGPT
    \item Feature Combinatorial Optimization
\end{enumerate}
ベースライン手法の詳細は4.2節で述べる．

各手法で以下の2種類の出力方法でラベルを生成する．
\begin{enumerate}
    \item 通常出力（normal output）：ラベル長に制限を設けずに出力
    \item 短出力（minimal output）：ラベル長を制限（例：10単語以内）して出力
\end{enumerate}
3つの手法それぞれで通常出力と短出力のラベルを生成し，合計6種類のラベルセットで被験者実験を行う．

ラベルの生成元となる画像には，Matterport3Dデータセットを使用する．データセット内に含まれる，同一地点から撮影した部屋の画像を結合することによってパノラマ画像を得る．パノラマ画像を1つの部屋を表す概念として扱い，いくつかの部屋のパノラマ画像に対してラベリングを行う．データセットの詳細は4.1.1節で述べる．


被験者実験はAmazon Mechanical Turk（AMT）を使用して行う．AMTはマイクロタスク型のクラウドソーシングサービスである．ワーカーに対してタスクをリクエストし，ワーカーがアクションを行い，その結果を回収する．

本実験では，ワーカーに複数の画像とラベルを与え，ラベルに紐づく画像を選択してもらう．AMTタスクの詳細は4.1.2節で述べる．

以上の実験全体の流れは以下の通りである．
\begin{enumerate}
    \item 画像の特徴を捉えたラベルを生成する．3つの手法（ChatGPT，Pragmatic ChatGPT，FCO）を用いて，画像集合からラベルを生成する．各手法ごとに通常出力と短出力のラベルを生成し，合計6種類のラベルセットを得る．
    \item AMTによる被験者実験でラベルを評価する．ワーカーに1つのラベルと複数の画像を与え，ラベルが説明している画像を正しく選択できるかを調査する．ラベルが説明している画像を正しく選択できた割合を正答率として，各手法の正答率を比較する．
\end{enumerate}

以上の実験の流れをまとめた図を図\ref{fig:flow_example}に示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figures/flow.png}
  \caption{実験の流れ}
  \label{fig:flow_example}
\end{figure}

\subsection{データセット}

実験では，Matterport3Dデータセット\footnote{https://niessner.github.io/Matterport/}を使用する．

Matterport3Dデータセットは，90の建物から成る，194,400枚のRGB-D画像による大規模なRGB-Dデータセットである．

本実験では，データセットに含まれる画像に対してパノラマ画像化処理を行った後，寝室を撮影した画像10枚を抽出して実験に使用した．

パノラマ画像化処理について，詳細を述べる．
データセットは，上下と水平方向の合わせて3回，それを60度ずつ横方向にずらして6回，計18回の撮影を同一の地点で行った画像群で構成されている．本実験では，同一地点で撮影した18枚の画像を適切な位置で結合する処理を，すべての画像に対して行うことで，各撮影地点ごとにパノラマ画像を作成した．

生成したパノラマ画像の例を図\ref{fig:panorama_example}に示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figures/panorama.jpeg}
  \caption{同一地点で撮影した画像18枚を結合したパノラマ画像}
  \label{fig:panorama_example}
\end{figure}

実験では，パノラマ画像の中から寝室を撮影した画像10枚を抽出して使用した．

\paragraph{パノラマ画像を実験で使用する理由}
画像に含まれる特徴量を均一化するためである．データセットに含まれる画像の中には，部屋全体をきれいに写した画像や，壁のみが写っている画像などがある．部屋全体を移した画像はラベリングの対象として適切だが，壁のみが写っている画像はラベリングする対象としては不適切である．そのため，パノラマ画像化処理を行うことで，すべての画像に十分な特徴が含まれ，実験に使用するのに適した画像を得ることができる．

\paragraph{寝室の画像のみを抽出する理由}
実験の難易度を適切に設定するためである．データセットにはキッチンやバスルーム，リビングなど，多種多様な地点で撮影した画像が含まれている．違う種類の部屋の画像に対してラベリングを行った場合，ラベルと画像の区別が簡単になりすぎてしまい，各手法の評価が適切に行えなくなる懸念がある．そのため，寝室の画像のみを抽出することで，実験の難易度を適切な水準に設定することを狙った．

\subsection{Amazon Mechanical Turk：AMTの概要}

Amazon Mechanical Turk（AMT）はマイクロタスク型に特化したクラウドソーシングサービスである．ワーカに対して何らかのタスク（アンケート，データラベリングなど）をリクエストし，ワーカがタスクに対して何らかのアクション（アンケートに回答する，データにラベルを付与するなど）を行い，ワーカが入力したデータを回収することで，問題を解決する．

実験では，4枚の画像からラベルに対応する画像を選ぶタスクを100回行い，その正答率を手法ごとに比較する．

実験で行うAMTのタスクの設定を以下に示す．

\begin{itemize}
  \item ワーカに対して4枚の画像とラベルを与える．
  \item ワーカは，ラベルに紐づくと考えられる画像を一枚選択する．
\end{itemize}

AMTタスクの例を図\ref{fig:amt_example}に示す．

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figures/amt.png}
  \caption{被験者に表示されるAMTタスクの例}
  \label{fig:amt_example}
\end{figure}

各手法ごとに，正解画像とラベル，それから被りなくランダムに抽出した3枚の不正解画像の組み合わせによって作成したタスクを100回行う．

タスクの作成手順の詳細は以下の通りである．
\begin{enumerate}
  \item 10枚の画像と，各画像に対応する10個のラベルが手法によって生成される．
  \item ある画像が正解となるタスクを10タスク作成する．このとき，不正解となる3つの画像は，ランダムに被りなく抽出して組み合わせる．
  \item 10枚の画像それぞれに対して2の処理を行い，100通りの組み合わせのタスクを作成する．
\end{enumerate}

\subsection{比較手法}

実験では，6種類の方法で出力したラベルを使用して比較実験を行う．

ラベルの生成には以下の3つの手法を用いる．
\begin{enumerate}
    \item ChatGPT(ベースライン手法)
    \item Pragmatic ChatGPT(PCG)
    \item Feature Combinatorial Optimization(FCO)
\end{enumerate}

各手法で以下の2種類の出力方法でラベルを生成する．
\begin{enumerate}
  \item 通常出力（normal output）：ラベル長に制限をかけずに出力
  \item 短出力（minimal output）：ラベル長を制限（10単語以内など）して出力
\end{enumerate}

ベースライン手法とPCGでは，以下のプロンプトをラベル出力処理部分に追加することで，10単語以内でラベルを生成するように制御している．この10単語以内という制限下でのラベル生成を短出力とする．

\begin{figure}[H]
\begin{mdframed}[linewidth=1pt]
Sentences must be output within 10 words.
\end{mdframed}
\caption{ラベル長に10単語以内の制限を設けるプロンプト}
\label{fig:limiting_prompt}
\end{figure}


ラベル長に制限を設ける理由は，手法の実用性を検証するためである．無制限に長いラベルを生成することにより，理論上誤解を排除することは可能であるが，これは実用的ではない．従って，実験では，短いラベルによる誤解の可能性を低減できるかどうかについても検証を行う．これは，ラベルの長さが誤解可能性に与える影響を評価するために不可欠である．実際の応用においては，簡潔でありながら効果的なラベルが求められるため，短いラベルにおける性能評価は手法の実用性と妥当性を確認する上で重要である．

3手法それぞれで通常出力と短出力のラベルを生成し，合計6種類のラベル群のセットで被験者実験を行う．実験結果では，各手法で生成したラベル群の平均単語数もあわせて示す．

ベースライン手法によって生成されたラベルの例を以下に示す．

\begin{figure}[H]
\begin{mdframed}[linewidth=1pt]
Bright bedroom with large windows, modern decor, scenic view.
\end{mdframed}
\caption{出力されるラベルの例}
\label{fig:label_example}
\end{figure}

このようなラベルの集合を各手法で生成し実験に使用する．

以下，実験で比較する各手法の名前と内容を箇条書きで説明する．

\begin{enumerate}
  \item ChatGPT
  \begin{itemize}
  \item ChatGPTを使用して，1枚の画像を入力して1つのラベルを出力する手法．以下のプロンプトを与えて，画像に対するラベルを出力する．
  \begin{figure}[H]
    \begin{mdframed}[linewidth=1pt]
      Generate a one-sentence description that captures only three features of the room you have provided.
    \end{mdframed}
    \caption{ベースライン手法で使用するプロンプト}
    \label{fig:baseline_prompt}
  \end{figure}
\end{itemize}
  
  \item Pragmatic ChatGPT（PCG）
  \begin{itemize}
    \item ChatGPTに「話し手モデル」「聞き手モデル」を導入し，ラベル改善サイクルを10回行う手法．
  \end{itemize}
  
  \item Feature Combinatorial Optimization（FCO）
  \begin{itemize}
    \item ラベル生成に組合せ最適化アルゴリズムを導入した手法．特徴を7つ組み合わせることによってラベルの生成を行う．
  \end{itemize}
  
  \item ChatGPT minimal
  \begin{itemize}
    \item ChatGPTに単語長10単語までの制約を加えた手法．\ref{fig:limiting_prompt}のプロンプトを，ラベル出力部分に追加する．，
  \end{itemize}
  
  \item Pragmatic ChatGPT minimal
  \begin{itemize}
    \item Pragmatic ChatGPTに単語長10単語までの制約を加えた手法．\ref{fig:limiting_prompt}のプロンプトを，ラベル出力部分に追加する．
  \end{itemize}
  
  \item Feature Combinatorial Optimization minimal（FCO minimal）
  \begin{itemize}
    \item FCOにラベルの特徴量3個までの制限を加えた手法．
  \end{itemize}
\end{enumerate}

\section{実験結果と考察}

\subsection{実験結果}

表\ref{tab:accuracy_result}は，手法ごとのAMTタスクの正答率と，タスクに使用したラベルの平均単語数を示している．

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\hline
手法 & 正答率 & 平均単語数 \\
\hline
ChatGPT & 0.43 & 26.9 \\
Pragmatic ChatGPT & 0.40 & 20.7 \\
FCO & 0.27 & 26.7 \\
ChatGPT minimal & 0.31 & 7.5 \\
Pragmatic ChatGPT minimal & 0.33 & 8.1 \\
FCO minimal & 0.37 & 9.3 \\
\hline
\end{tabular}
\caption{手法ごとのAMTタスクの正答率と平均単語数}
\label{tab:accuracy_result}
\end{table}

短いラベル長の実験においてはFCO minimalの正答率が最も高くなり，Pragmatic ChatGPT minimalもベースライン手法であるChatGPT minimalの正答率を上回る結果となった．

長いラベル長の実験においてはFCOとPragmatic ChatGPTのどちらもベースラインの正答率を下回った．

また，短いラベル長の実験においては，平均単語数と正答率に若干の相関があった．

\subsection{考察}
以上の結果から，ラベルの長さに制限がある場合において，提案手法が一定の効果を持つことがわかった．その理由として次のことが考えられる．限られた単語数で画像の特徴を正確に表現することは困難である．この場合，各ラベルに含まれる特徴の組み合わせによりラベルの識別性を向上させる必要がある．この点において，提案手法は各ラベルの識別性の向上を主軸としてラベルを生成するため，ベースライン手法を上回る結果となったと考えられる．


また，ラベル長に制限が無い場合，提案手法はうまく機能しないことがわかった．その理由として次のことが考えられる．単語数の制限が無い場合，識別性の向上のために多くの単語を使用することで，提案手法は画像との関連性が低い単語をラベルに含めてしまう可能性がある．これにより対応する画像の特徴を正確に表現できないラベルが出力され，ベースライン手法に劣る結果となったと考えられる．


提案手法の改善案として，ラベルの説明性を担保する機構の追加が挙げられる．これにより，説明性と識別性のバランスを保つことができるようになり，ラベルの誤解可能性を減らすことができると考えられる．

% 結論
\chapter{おわりに}

本研究では，画像に対するラベル生成の問題を語用論的な観点から解決する試みを行った．特に，話し手モデルと聞き手モデルを導入し，その対話を通じてラベルの改善を図る新たなアプローチを提案した．

提案手法は，話し手モデルが作成したラベルを聞き手モデルが評価し，そのフィードバックに基づいてラベルを再生成するプロセスを繰り返すことで，より適切なラベルの生成を目指す．これにより，生成されたラベルが画像を一意に特定できるものであることが期待される．

また，本研究では生成したラベルの評価にAmazon Mechanical Turkを利用し，生成されたラベルが人間にとってどの程度理解しやすいかを検証した．その結果，提案手法によって生成されたラベルは，特にラベル長に制約がある場合において，ベースライン手法よりも優れた結果を示した．これは，提案手法がラベルの識別性を向上させることに重点を置いて設計されているためである．

今後の課題としては，より多様な画像やシーンに対するラベル生成の実施と，提案手法の汎用性の評価が挙げられる．また，聞き手モデルの評価基準やフィードバックの精度を向上させることも重要である．これらの課題を解決することで，本手法はさらに広範な応用が可能となると考えられる．

\chapter*{謝辞}
\addcontentsline{toc}{chapter}{\numberline{}謝辞}	% 目次で左詰めするなら \numberline{} を削除する．

本研究の一部は，JST CREST (\#JPMJCR22M2) の助成によって行われた．

\newpage

\addcontentsline{toc}{chapter}{\numberline{}参考文献}	% 目次で左詰めするなら \numberline{} を削除する．
\renewcommand{\bibname}{参考文献}

\bibliographystyle{junsrt}
\bibliography{reference}

\end{document}
